# Setup Amazon EKS cluster

The scripts of this section will launch an EKS cluster, setup a EFS file system for persistence, and configure a `bastion` host that you can login and start a Hyperledger Fabric network.  The configuration file [env.sh](./env.sh) specifies the number and type of EC2 instances used by the EKS cluster, e.g., 3 `t2.medium` instances are used by the default configuration.

## Configure AWS account connection
Install [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html) if you have not already done so.  Mac users can use the [bundled installer](https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html).

Create an AWS user `access key` if you do not already have one or do not remember the key.  In a web browser, login to [IAM console](https://console.aws.amazon.com/iam/home). On the user page, `Users > your-name@your-company.com`, choose `Security credentials` tab, and click `Create access key`. Take a note of the key-id and access-key before closing the window, and use the following AWS CLI command to configure your AWS connection:
```
aws configure
```
It should record the AWS configuration in 2 files in your local home directory, i.e., `$HOME/.aws/config`, which looks similar to the following:
```
[default]
region = us-west-2
output = json

[profile prod]
role_arn = arn:aws:iam::123456789012:role/TIBCO/Administrator
source_profile = default
region = us-west-2
output = json
```
and `$HOME/.aws/credentials`, which looks like
```
[default]
aws_access_key_id = ABCDEFGHIJ1234567890
aws_secret_access_key = abcdefghijklmnopqrstuvwxyz1234567890ABCD
```
If you need to work with a role for a different AWS account, you can add a `profile` definition to the `config` file, similar to the `prod` profile in the above sample (Your AWS administrator can provide you the `role_arn`).  To use the profile `prod` as the default, you can set the environment variable, e.g.,
```
export AWS_PROFILE=prod
```
## Start EKS cluster
Create and start the EKS cluster with all defaults:
```
cd ./aws
./create-all.sh
```
This script accepts 3 parameters for you to specify a different AWS environment, e.g.,
```
./create-all.sh fab us-west-2 prod
```
would create an EKS cluster with name prefix of `fab`, in the AWS region of `us-west-2`, using AWS account profile `prod`.

Wait 20-30 minutes for the cluster nodes to startup.  When the cluster is up, it will print a line, such as:
```
ssh -i ./fabric-operation/aws/config/fab-keypair.pem ec2-user@ec2-34-213-140-181.us-west-2.compute.amazonaws.com
```
You can use this command to login to the `bastion` EC2 instance and create a Hyperledger Fabric network in the EKS cluster.  Note that a `fab-keypair` is generated by the scripts and stored under the `config` folder.  The scripts also set the env variable `AWS_PROFILE` if a role is specified in the above command.

Note also that the scripts have set the security group such that the `bastion` host can be accessed by only your workstation's current IP address. If your IP address changes, you'll need to login to AWS and update the security rule to open the ssh port 22 to your new IP address.

## Prepare EKS cluster and EFS file system for Hyperledger Fabric
Log on to the `bastion` host, e.g., (your real host name will be different):
```
ssh -i ./config/fab-keypair.pem ec2-user@ec2-34-213-140-181.us-west-2.compute.amazonaws.com
```
After login, you'll notice that everything is automatically setup for you.  You may verify the following configurations.
* `df` command should show that an `EFS` storage is already mounted at `/mnt/share`;
* `kubectl get pod,svc --all-namespaces` should show you the Kubernetes system services and PODs;
* `ls ~` should show you that the latest code of this project is already downloaded at `$HOME/fabric-operation`.

## Start and test Hyperledger Fabric network
Following steps will start and smoke test the default Hyperledger Fabric network with 2 peers, and 3 orderers using `etcd raft` consensus. You can learn more details about these commands [here](../README.md).

### Create namespace for the network operator
```
cd ../namespace
./k8s-namespace.sh netop1 aws
```
This command creates a namespace for the default Fabric operator company, `netop1`, and sets it as the default namespace. You can verify this step using the following commands:
* `kubectl get namespaces` should show a list of namespaces, including the new namespace `netop1`;
* `kubectl config current-context` should show that the default namespace is set to `netop1`.

### Start CA server and create crypto data for the Fabric network
```
cd ../ca
./start-ca.sh netop1 aws
./bootstrap.sh netop1 aws
```
This command starts 2 CA servers and a CA client, and generates crypto data according to the network specification, [netop1.env](../config/netop1.env).  You can verify the result using the following commands:
* `kubectl get pod,svc` should list 3 running PODs: `ca-server`, `tlsca-server`, and `ca-client`;
* `ls /mnt/share/netop1.com/` should list folders containing crypto data, i.e., `crypto`, `orderers`, `peers`, `cli`, and `tool`.

### Generate genesis block and channel creation tx
```
cd ../msp
./bootstrap.sh netop1 aws
```
This command starts a Kubernetes Job to generate the genesis block and transaction for creating a test channel `mychannel` based on the network specification.  You can verify the result using the following commands:
* `kubectl get jobs` should list a completed `job/tool` (note that you may need to wait a few seconds before it shows 1 completion);
* `ls /mnt/share/netop1.com/tool` should show the generated artifacts: `genesis.block`, `channel.tx`, `anchors.tx`, and `configtx.yaml`.

### Start Fabric network
```
cd ../network
./start-k8s.sh netop1 aws
```
This command starts the orderers and peers using the crypto and genesis block created in the previous steps.  You can verify the network status using the following commands:
* `kubectl get pod,svc` should list 3 running orderers and 2 running peers;
* `kubectl logs peer-1 -c peer` should show the logs of `peer-1`, that shows its successfully completed gossip communications with `peer-0`.
* `ls /mnt/share/netop1.com/orderers/orderer-0/data` shows persistent storage of the `orderer-0`, similar to other orderer nodes;
* `ls /mnt/share/netop1.com/peers/peer-0/data` shows persistent storage of the `peer-0`, similar to other peer nodes.

### Smoke test of the Fabric network
```
cd ../network
./k8s-test.sh netop1 aws
```
This command creates the test channel `mychannel`, installs and instantiates a test chaincode, and then executes a transaction and a query to verify the working network.  You can verify the result as follows:
* The last result printed out by the test should be `90`;
* Orderer data folder, e.g., `/mnt/share/netop1.com/orderers/orderer-0/data` would show a block file added under the chain of a new channel `mychannel`;
* Peer data folder, e.g., `/mnt/share/netop1.com/peers/peer-0/data` would show a new chaincode `mycc.1.0` added to the chaincode folder, and a transaction block file created under the chain of `mychannel`.

### Stop Fabric network and cleanup persistent data
```
cd ../network
./stop-k8s.sh netop1 aws true
```
This command shuts down orderers and peers, and the last argument `true` means to delete all persistent data as well.  If you do not provide the 3rd argument, it would keep the test ledger on the `EFS` file system, and so it can be loaded when the network restarts.  You can verify the result using the following command.
* `kubectl get svc,pod` should not list any running orderers or peers;
* The orderers and peers' persistent data folder, e.g., `/mnt/share/netop1.com/peers/peer-0/data` would be deleted if the 3rd argument of the above command is `true`.

## Clean up all AWS artifacts
You can clean up every thing created in AWS when they are no longer used, i.e.,
```
cd ./aws
./cleanup-all.sh fab us-west-2 prod
```
This will clean up the EKS cluster and EFS file system created in the previous steps.  Make sure that you supply the same parameters to the `cleanup-all.sh` as that of the previous call to the `create-all.sh` if they are different from the default values.  The `AWS_PROFILE` env should also be set the same as that when `create-all.sh` was called previously.

It may take a while for AWS actually cleans up everything.  If the script prints out errors, you can re-run this script to make sure that everything is deleted so that you are not charged by Amazon for processes hanging around in AWS.

## TIPs

### Use kubectl from localhost
If your local workstation has `kubctl` installed, and you want to execute `kubectl` commands directly from the localhost, instead of going through the `bastion` host, you can set the env,
```
export KUBECONFIG=/path/to/fabric-operation/aws/config/config-fab.yaml
```
where the `/path/to` is the location of this project on your localhost, and `config-fab.yaml` is named after the `ENV_NAME` configured in [`env.sh`](./env.sh).  The file is created for you when you execute the `create-all.sh`, and it is valid only while the EKS cluster is running.

You can then use `kubectl` commands against the Amazon EKS cluster from your localhost directly, e.g.,
```
kubectl get pod,svc --all-namespaces
```
### Set default Kubernetes namespace
The containers created by the scripts will use the name of a specified operating company, e.g., `netop1`, as the Kubernetes namespace.  To save you from repeatedly typing the namespace in `kubectl` commands, you can set `netop1` as the default namespace by using the following commands:
```
kubectl config view
kubectl config set-context netop1 --namespace=netop1 --cluster=fab-eks-stack.us-west-2.eksctl.io --user=1572660907000277000@fab-eks-stack.us-west-2.eksctl.io
kubectl config use-context netop1
```
Note to replace the values of `cluster` and `user` in the second command by the corresponding output from the first command.  This configuration is automatically done on the bastion host when the [`k8s-namespace.sh`](../namespace/k8s-namespace.sh) script is called.